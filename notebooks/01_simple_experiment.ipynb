{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3c9c05",
   "metadata": {},
   "source": [
    "# 01 - Demonstrating packages in a simple experiment\n",
    "\n",
    "This notebook demonstrates the end-to-end process of using the privacy fingerprint package to conduct an experiment. Before running this notebook you must have completed all the installation and setup steps in the README. The steps covered are:\n",
    "\n",
    "* Generate structured dummy data with Synthea\n",
    "* Convert the structured records to unstructured clinical notes using a large language model (LLM)\n",
    "* Extract identifiers from the clinical notes using named entity recognition (NER)\n",
    "* Standardise the NER output\n",
    "* Run pycorrectmatch to assess the privacy risk in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import privacy_fingerprint.extract.aws_comprehend as aws\n",
    "import privacy_fingerprint.generate.language_model as llm\n",
    "import privacy_fingerprint.generate.synthea as synthea\n",
    "from privacy_fingerprint.common.config import (\n",
    "    load_experiment_config,\n",
    "    load_experiment_config_from_file,\n",
    "    load_global_config_from_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9198f",
   "metadata": {},
   "source": [
    "Options within the process are controlled using two config files, one for global settings such as API keys, and another for a particular experiment. Example config files are available in the 'configs' directory. These example configs contain default settings but require modification to reflect your set-up of Julia, Synthea, and AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bee258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move and modify the config files\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_config.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")\n",
    "\n",
    "# Config options can be modified in-line also. To keep this notebook/experiment small the number\n",
    "# of patient records generated will be changed to 10.\n",
    "expt_config = load_experiment_config()\n",
    "expt_config.synthea.encounter_type = \"Encounter for symptom\"\n",
    "expt_config.synthea.num_records = 10\n",
    "# Note that to apply in-line changes you must reload the settings.\n",
    "load_experiment_config(expt_config.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.score import PrivacyRiskScorer, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ccd0a",
   "metadata": {},
   "source": [
    "Synthea generates a directory full of events according to the output_dir argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../experiments/01_simple_experiment/\"\n",
    "# os.mkdir(output_dir)\n",
    "export_directory = os.path.join(output_dir, \"synthea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21cc3a",
   "metadata": {},
   "source": [
    "With the directory setup we can generate records. This may take some time, especially when generating a large number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b68366",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthea_records = synthea.generate_records(export_directory)\n",
    "print(f\"Generated {len(synthea_records)} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdaa0ff",
   "metadata": {},
   "source": [
    "Despite requesting 10 records, we might not get 10 records. There are two reasons:\n",
    "\n",
    "* Synthea will generate individuals and track them through time. If an individual dies they will not be counted towards `num_records` and Synthea will continue. The result is `num_records` living individual plus any that have died.\n",
    "* It is also possible for less than `num_records` to be returned if some generated individuals did not have the medical encounter type specified in the config file.\n",
    "\n",
    "We can now use the structured Synthea records to generate general medical notes for some encounters. This step calls the LLM API and returns unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ae451",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note_generator = llm.LMGenerator()\n",
    "llm_results = clinical_note_generator.generate_text(synthea_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e71de",
   "metadata": {},
   "source": [
    "We can print a sample of the generated notes to read the model outputs. Note the text generator returns a generator not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results = list(llm_results)\n",
    "print(*llm_results[:5], sep=\"\\n\\n------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0cb9",
   "metadata": {},
   "source": [
    "We then perform the \"reverse\" step by using an NER service (AWS ComprehendMedical) to extract the information we injected into the unstructured records again. This is the most expensive step of the process, so a helper formula is provided based on the costs as of March 10th 2023. Updated costs can be found on the AWS documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef410570",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated cost is $\", aws.calculate_ner_cost(llm_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7d390",
   "metadata": {},
   "source": [
    "We commit to this cost! and begin the extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_extract = aws.ComprehendExtractor()\n",
    "ner_records = [\n",
    "    aws_extract.extract_record(medical_note) for medical_note in llm_results\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e77f05",
   "metadata": {},
   "source": [
    "The result is a list of dictionaries of extracted entities. Individual entities, their text spans, and the NER's confidence in the output can be viewed in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_records[0][\"Entities\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb09903a",
   "metadata": {},
   "source": [
    "The raw output of the NER is converted to a standardised format used within this package prior to scoring. The DEFAULT set of identifiers is used, but your own identifiers can be included if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f362324",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_results = aws.prepare_common_records(\n",
    "    aws.DEFAULT_IDENTIFIERS, ner_records\n",
    ")\n",
    "print(common_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72368a6c",
   "metadata": {},
   "source": [
    "We then need to convert these results into a table. Given some identifiers may have multiple values (such as disease, or prescription if people are receiving multiple medications) we must encode these in a particular manner. By default, we are using rarest encoding as this does not generate as many columns and runs more quickly. One-hot encoding is also available but the maximum number of columns should be tightly constrained to avoid excessive run times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01babd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_records = preprocess(common_results).fillna({\"nhs_number\": \"\"})\n",
    "df_records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0209380",
   "metadata": {},
   "source": [
    "Finally build a risk scorer. This class is a wrapper around the pycorrectmatch project allowing us to have meaningful column names. Since this demo set is only 10 records, which are likely all unique we limit ourselves to looking at only two columns, gender and nhs_number.\n",
    "\n",
    "The scorer is fit to the provided dataset of genders and nhs numbers, and the individual uniqueness calculated for each row. This represents the likelihood of re-identifying them correctly, for example a score of .5 means there are 2 people sharing these features, so you have a 50% chance of identifying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_scorer = PrivacyRiskScorer()\n",
    "print(\"Fitting\")\n",
    "risk_scorer.fit(df_records[[\"gender\", \"nhs_number\"]])\n",
    "print(\"Prediciting\")\n",
    "risk_scorer.predict(df_records[[\"gender\", \"nhs_number\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd14c3",
   "metadata": {},
   "source": [
    "At this stage we know the records that most compromise privacy and might require actions to de-identify.\n",
    "\n",
    "The analysis can be extended one step further to inform the best de-identification steps. The relative contribution of the different identifiers can be calculated using the explain module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33080ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.explain import PrivacyRiskExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6404bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = risk_scorer.map_records_to_copula(\n",
    "    df_records[[\"gender\", \"nhs_number\"]]\n",
    ")\n",
    "N_FEATURES = df_records[[\"gender\", \"nhs_number\"]].shape[1]\n",
    "print(N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP takes a while to run - a progress bar appears when running SHAP\n",
    "explainer = PrivacyRiskExplainer(risk_scorer.predict_transformed, N_FEATURES)\n",
    "# Calculating shapley values using the transformed_dataset\n",
    "local_shapley_df, global_shap, exp_obj = explainer.explain(transformed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b8cf9",
   "metadata": {},
   "source": [
    "The results can then to visualised. First, we can look at the contribution of each identifier across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b86781",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.plot_global_explanation(exp_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2ff2b",
   "metadata": {},
   "source": [
    "The contribution of each identifier for each record can also be visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.plot_local_explanation(exp_obj, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81b9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "41fa86903fbf5844d82e67d8d932c6047b980f2d9905341364c3692a5481bed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
