{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Calculating and visualising the SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    "\n",
    "\n",
    "  * demonstate how to use the `explain` module\n",
    "  * visualise both global and local shapley values\n",
    "  * rank the scored dataset from riskiest to least risky record\n",
    "\n",
    "\n",
    "This module uses the [SHAP library](https://shap.readthedocs.io/en/latest/)\n",
    "\n",
    "Pycorrectmatch moves from real record values to the copula data representation, where 1 is the most common entry in the column, 2 is the second and so on until the number of unique values for each feature.\n",
    "\n",
    "Our baseline record could be the least unique record, i.e. it has the most common values of each feature. In the case of the copula representation, this is a vector of 1s, size 1 by n the number of features. The individual uniqueness of this vector would be a number close to zero, as this represents the least unique record.\n",
    "\n",
    "This is useful to for explainability. We can use this baseline as something that is effectively the same as not having information. The individual shapley values per record then would add up approx to their individual privacy risk score:\n",
    "\n",
    "`model.predict(X.iloc[[0]])= shap_result.base_values[0] + sum(shap_result.values[0])`\n",
    "\n",
    "\n",
    "where `shap_result.base_values[0] is the baseline and we assume ~0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.common.config import (\n",
    "    load_experiment_config,\n",
    "    load_experiment_config_from_file,\n",
    "    load_global_config_from_file,\n",
    ")\n",
    "\n",
    "# Example config files are available in the config directory.\n",
    "# They will need to be modified with the path to the Julia executable\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_config.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = load_experiment_config()\n",
    "experiment_config.scoring.encoding_scheme = \"rarest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import privacy_fingerprint.extract.aws_comprehend as aws\n",
    "from privacy_fingerprint.explain import PrivacyRiskExplainer\n",
    "from privacy_fingerprint.score import PrivacyRiskScorer, encode, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset will be loaded from the directory created in notebook 2.\n",
    "output_dir = \"../experiments/02_generate_dataset/\"\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\")) as fp:\n",
    "    ner_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The format of the NER records must be standardised to enable scoring\n",
    "common_ner_results = aws.prepare_common_records(\n",
    "    aws.DEFAULT_IDENTIFIERS, ner_records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_dataset = preprocess(common_ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep a limited number of columns for the purposes of the example since\n",
    "# shapley values take a while to be calculated\n",
    "cols_to_keep = [\"gender\", \"ethnicity\", \"disease\", \"treatment\", \"prescriptions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_ethnicity(text):\n",
    "    text = text.lower()\n",
    "    if text == \"\":\n",
    "        return \"unknown\"\n",
    "    mentions = defaultdict(int)\n",
    "    for ethnicity, label in [\n",
    "        (\"white\", \"white\"),\n",
    "        (\"black\", \"black\"),\n",
    "        (\"african\", \"black\"),\n",
    "        (\"asian\", \"asian\"),\n",
    "        (\"indian\", \"asian\"),\n",
    "        (\"pakistani\", \"asian\"),\n",
    "        (\"chinese\", \"asian\"),\n",
    "    ]:\n",
    "        if ethnicity in text:\n",
    "            mentions[label] += 1\n",
    "    if len(mentions) > 1:\n",
    "        return \"mixed\"\n",
    "    elif len(mentions) == 1:\n",
    "        return list(mentions.keys())[0]\n",
    "    else:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    \"gender\": lambda x: x.lower()\n",
    "    if x.lower() in [\"female\", \"male\"]\n",
    "    else \"unknown\",\n",
    "    \"ethnicity\": simplify_ethnicity,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pycorrectmatch required the dataset to be encoded, as we have seen in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset, lookup = encode(\n",
    "    pcm_dataset[cols_to_keep].transform(\n",
    "        {i: transformations.get(i, lambda x: x) for i in cols_to_keep}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the privacy risk scorer to transform the dataset to the values of the copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = PrivacyRiskScorer()\n",
    "pop_uniqueness = scorer.calculate_population_uniqueness(encoded_dataset)\n",
    "print(\"Population uniqueness: \", pop_uniqueness)\n",
    "# Here we fit the model, this has to happen first before calculating scores or transforming\n",
    "scorer.fit(encoded_dataset)\n",
    "# This is the transformed dataset from the real record values to the marginal values\n",
    "transformed_dataset = scorer.map_records_to_copula(encoded_dataset)\n",
    "N_FEATURES = encoded_dataset.shape[1]\n",
    "print(N_FEATURES)\n",
    "# Calculating individual privacy risk scores\n",
    "pcm_scored_dataset = scorer.predict(encoded_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the explainer to pass the transformed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP takes a while to run - a progress bar appears when running SHAP\n",
    "explainer = PrivacyRiskExplainer(scorer.predict_transformed, N_FEATURES)\n",
    "# Calculating shapley values using the transformed_dataset\n",
    "local_shapley_df, global_shap, exp_obj = explainer.explain(transformed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise global and local shapley values\n",
    "\n",
    "The SHAP library has plotting functions that can visualise the shap results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean shap values - global explanation\n",
    "explainer.plot_global_explanation(exp_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the local shap values for a particular record\n",
    "explainer.plot_local_explanation(exp_obj, 985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank records by overall privacy risk\n",
    "\n",
    "The sum of the individual shapley values should be equal to the individual privacy risk score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the original record dataset sorted by individual risk score\n",
    "sorted_pcm_df = pcm_dataset[cols_to_keep].loc[\n",
    "    pcm_scored_dataset.sort_values(ascending=False).index\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is equivalent to sorting it by descending order of the shapley sums per row\n",
    "\n",
    "\n",
    " `s = local_shapley_df.sum(axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_local_shapley_df = local_shapley_df.loc[\n",
    "    pcm_scored_dataset.sort_values(ascending=False).index\n",
    "]\n",
    "\n",
    "ranked_local_shapley_df_w_score = ranked_local_shapley_df.copy(deep=True)\n",
    "ranked_local_shapley_df_w_score[\"score\"] = pcm_scored_dataset.sort_values(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following heatmap visualises the individual shap values on the ranked dataframe- ranked from riskiest to least risky record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(\n",
    "    ranked_local_shapley_df,\n",
    "    cmap=sns.light_palette(\"r\", as_cmap=True),\n",
    "    annot=False,\n",
    ")\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the local shap values for the riskiest record\n",
    "explainer.plot_local_explanation(exp_obj, ranked_local_shapley_df.iloc[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
