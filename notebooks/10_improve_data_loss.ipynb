{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Improvements in the data loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "\n",
    "- documents further assessment of data loss and the performance of the NER component\n",
    "\n",
    "- demonstrates how improvements can be achieved and\n",
    "\n",
    "- provides direction of future work.\n",
    "\n",
    "\n",
    "In the same folder, notebook `03_evaluate_data_loss`  evaluates the loss of identifiers in the Synthea-LLM-NER pipeline. Further research showed that there can be significant improvements in the usage by the LLM and the subsequent detection by the NER of personal identifiers.\n",
    "\n",
    "This notebook documents such a successful attempt. This notebook also assumes you have read the previous notebooks.\n",
    "\n",
    "- new dataset generation using the same synthea dataset as the previous notebooks but with a different prompt for the LLM\n",
    "- light pre-processesing of the synthea data\n",
    "- evaluate data loss betwwen the Synthea-LLM-NER steps\n",
    "- assess the effect on the privacy risk score \n",
    "\n",
    "\n",
    "Future work in the repo source code could include adding `age` as a field in the `Record` class and light synthea data preprosessing before being fed as input to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import privacy_fingerprint.extract.aws_comprehend as aws\n",
    "import privacy_fingerprint.generate.language_model as llm\n",
    "import privacy_fingerprint.generate.synthea as synthea\n",
    "from privacy_fingerprint.common import compare_common_records\n",
    "from privacy_fingerprint.common.config import (\n",
    "    load_experiment_config,\n",
    "    load_experiment_config_from_file,\n",
    "    load_global_config_from_file,\n",
    ")\n",
    "from privacy_fingerprint.score import PrivacyRiskScorer, encode, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configs, change the LLM prompt and create output dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"You are an InstructGPT. Describe this patient as if you were a medical doctor and \"\n",
    "    \"include in your answer the provided date of birth, age and the \"\n",
    "    \"NHS number of the patient.\"\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = load_global_config_from_file(\"../global_config.yaml\")\n",
    "experiment_config = load_experiment_config_from_file(\n",
    "    \"../experiment_config.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we change the LLM prompt in a notebook.\n",
    "# This change could also happen in the config file.\n",
    "expt_config = load_experiment_config()\n",
    "expt_config.openai.prompt = prompt\n",
    "expt_config.synthea.encounter_type = (\n",
    "    \"Encounter for symptom\"  # as it had been created in the original dataset\n",
    ")\n",
    "load_experiment_config(expt_config.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outputs of this notebook will be saved to a directory\n",
    "output_dir = \"../../experiments/10_improve_data_loss\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously generated synthea\n",
    "\n",
    "Here you need to replace `synthea_dir` with the directory where the synthea output was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a previously generated set of records they can be loaded as follows:\n",
    "synthea_dir = \"<...>\"\n",
    "\n",
    "with open(os.path.join(synthea_dir, \"synthea_dataset.json\")) as fp:\n",
    "    synthea_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing before feeding the synthea data to the LLM\n",
    "\n",
    "Here we keep from the ISO format of the visit date the date (default format \"YYYY-MM-DD\"), we calculate the patient's age from the provided date of visit and date of birth dates (i.e. the patient's age at the time of visit), and we remove the 'visit type' field, which although necessary when creating the synthea records, it does not add any information to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in synthea_records:\n",
    "    record[\"visit date\"] = str(\n",
    "        pd.to_datetime(record[\"visit date\"], errors=\"coerce\").date()\n",
    "    )\n",
    "    record[\"age\"] = (\n",
    "        pd.to_datetime(record[\"visit date\"], errors=\"coerce\").year\n",
    "        - pd.to_datetime(record[\"date of birth\"], errors=\"coerce\").year\n",
    "    )\n",
    "    del record[\"visit type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create free-text clinical notes with the LLM\n",
    "\n",
    "We pass to the LLM the promt as defined in this notebook, as well as the processed synthea records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note_generator = llm.LMGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results = clinical_note_generator.generate_text(synthea_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results = list(llm_results)\n",
    "print(*llm_results[:5], sep=\"\\n\\n------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to save the generated LLM results\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(llm_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from the unstructured text using the NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then perform the \"reverse\" step by using an NER service (AWS ComprehendMedical) to extract the information we injected into the unstructured records again. This is the most expensive step of the process, so a helper formula is provided based on the costs as of March 10th 2023. Updated costs can be found on the AWS documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated cost is $\", aws.calculate_ner_cost(llm_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_extract = aws.ComprehendExtractor()\n",
    "ner_records = [\n",
    "    aws_extract.extract_record(medical_note) for medical_note in llm_results\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of dictionaries of extracted entities. Individual entities, their text spans, and the NER's confidence in the output can be viewed in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to save the extracted ner results\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(ner_records, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to common format and compare\n",
    "\n",
    "In order to compare the synthea records to the extracted ner records, we need to standardise their format. \n",
    "\n",
    "In this experiment we also injected the information `age` which is not included in the common format, so we will compare this apart. \n",
    "\n",
    "Further work could include adding `age` to the common format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_synthea_results = synthea.prepare_common_records(\n",
    "    synthea.DEFAULT_IDENTIFIERS, synthea_records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ner_results = aws.prepare_common_records(\n",
    "    aws.DEFAULT_IDENTIFIERS, ner_records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_comparison_summary = []\n",
    "for s, n in zip(common_synthea_results, common_ner_results):\n",
    "    overall_score, max_score, summary = compare_common_records(s, n)\n",
    "    record_comparison_summary.append(summary)\n",
    "\n",
    "record_comparison_summary = pd.DataFrame(record_comparison_summary)\n",
    "record_comparison_summary.plot.box(rot=90, ylabel=\"Data recovery (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the `age` field\n",
    "\n",
    "This field is not currently in the common format, so it is compared separately. In the future this field should be included in the common Record format, so this step would be redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract age from ner\n",
    "def _extract_entity_type(record, entity_type):\n",
    "    return [i for i in record if i[\"Type\"] == entity_type]\n",
    "\n",
    "\n",
    "def extract_age(record):\n",
    "    candidates = _extract_entity_type(record, \"AGE\")\n",
    "    if len(candidates) == 0:\n",
    "        return None\n",
    "    return [i[\"Text\"] for i in candidates][0]\n",
    "\n",
    "\n",
    "# extract age from synthea\n",
    "def extract_age_sythea(record):\n",
    "    return record[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for s, n in zip(synthea_records, ner_records):\n",
    "    age_synthea = extract_age_sythea(s)\n",
    "    age_ner = extract_age(n[\"Entities\"])\n",
    "    data.append([age_synthea, age_ner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\"age_synthea\", \"age_ner\"],\n",
    ")\n",
    "age_df[\"age\"] = age_df.apply(\n",
    "    lambda row: fuzz.ratio(str(row[\"age_synthea\"]), str(row[\"age_ner\"])),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_comparison_w_age = record_comparison_summary.copy(deep=True)\n",
    "record_comparison_w_age[\"age\"] = age_df[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"nhs_number\",\n",
    "    \"name\",\n",
    "    \"age\",\n",
    "    \"date_of_birth\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"disease\",\n",
    "    \"date_of_visit\",\n",
    "    \"department\",\n",
    "    \"treatment\",\n",
    "    \"prescription\",\n",
    "    \"provider\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_comparison_w_age[cols].plot.box(rot=90, ylabel=\"Data recovery (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the privacy risk scores of both synthea (initial) and ner (extracted) records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_ethnicity(text):\n",
    "    text = text.lower()\n",
    "    if text == \"\":\n",
    "        return \"unknown\"\n",
    "    mentions = defaultdict(int)\n",
    "    for ethnicity, label in [\n",
    "        (\"white\", \"white\"),\n",
    "        (\"black\", \"black\"),\n",
    "        (\"african\", \"black\"),\n",
    "        (\"asian\", \"asian\"),\n",
    "        (\"indian\", \"asian\"),\n",
    "        (\"pakistani\", \"asian\"),\n",
    "        (\"chinese\", \"asian\"),\n",
    "    ]:\n",
    "        if ethnicity in text:\n",
    "            mentions[label] += 1\n",
    "    if len(mentions) > 1:\n",
    "        return \"mixed\"\n",
    "    elif len(mentions) == 1:\n",
    "        return list(mentions.keys())[0]\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def simplify_date_of_birth(date):\n",
    "    dt = pd.to_datetime(date, errors=\"coerce\")\n",
    "    if pd.isnull(dt):\n",
    "        return None\n",
    "    else:\n",
    "        return 10 * (dt.year // 10)\n",
    "\n",
    "\n",
    "transformations = {\n",
    "    \"gender\": lambda x: x.lower()\n",
    "    if x.lower() in [\"female\", \"male\"]\n",
    "    else \"unknown\",\n",
    "    \"ethnicity\": simplify_ethnicity,\n",
    "    \"date_of_birth\": simplify_date_of_birth,\n",
    "}\n",
    "\n",
    "cols = [\n",
    "    \"date_of_birth\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"disease\",\n",
    "    \"symptoms\",\n",
    "    \"treatment\",\n",
    "    \"prescriptions\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate privacy risk score for ner records\n",
    "pcm_dataset = preprocess(common_ner_results)\n",
    "\n",
    "encoded_dataset, lookup = encode(\n",
    "    pcm_dataset[cols].transform(\n",
    "        {i: transformations.get(i, lambda x: x) for i in cols}\n",
    "    )\n",
    ")\n",
    "scorer = PrivacyRiskScorer()\n",
    "population_score = scorer.calculate_population_uniqueness(encoded_dataset)\n",
    "print(population_score)\n",
    "scorer.fit(encoded_dataset)\n",
    "e2e = {\n",
    "    \"population_score\": population_score,\n",
    "    \"individual_scores\": scorer.predict(encoded_dataset),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate privacy risk score for synthea records\n",
    "synthea_pcm_dataset = preprocess(common_synthea_results)\n",
    "\n",
    "encoded_dataset, lookup = encode(\n",
    "    synthea_pcm_dataset[cols].transform(\n",
    "        {i: transformations.get(i, lambda x: x) for i in cols}\n",
    "    )\n",
    ")\n",
    "scorer = PrivacyRiskScorer()\n",
    "population_score = scorer.calculate_population_uniqueness(encoded_dataset)\n",
    "print(population_score)\n",
    "scorer.fit(encoded_dataset)\n",
    "initial_records = {\n",
    "    \"population_score\": population_score,\n",
    "    \"individual_scores\": scorer.predict(encoded_dataset),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Population uniqueness on initial records\",\n",
    "    initial_records[\"population_score\"],\n",
    ")\n",
    "print(\"Population uniqueness on extracted records\", e2e[\"population_score\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(initial_records[\"individual_scores\"], e2e[\"individual_scores\"], \"k.\")\n",
    "ax.set_xlabel(\"Initial structured records\")\n",
    "ax.set_ylabel(\"NER extracted records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"initial\": initial_records[\"individual_scores\"],\n",
    "        \"extract\": e2e[\"individual_scores\"],\n",
    "    }\n",
    ")\n",
    "comparison[\"difference\"] = (comparison.initial - comparison.extract).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the ordering of records by privacy risk in the Synthea and extracted datasets\n",
    "def compare_scores(a, b, label, ax=None, color=None):\n",
    "    assert len(a) == len(b), \"Lengths must match\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    c = pd.DataFrame({\"a\": a, \"b\": b})\n",
    "    c = c.sort_values(\"b\")\n",
    "    c[\"b_rank\"] = range(1, 1 + len(a))\n",
    "    c = c.sort_values(\"a\")\n",
    "    c[\"a_rank\"] = range(1, 1 + len(a))\n",
    "    fraction_below = []\n",
    "    for i in range(len(a)):\n",
    "        fraction_below.append((c.iloc[:i].b_rank <= c.iloc[i].a_rank).sum())\n",
    "    if color:\n",
    "        ax.plot(fraction_below, label=label, color=color)\n",
    "    else:\n",
    "        ax.plot(fraction_below, label=label)\n",
    "    return ax\n",
    "\n",
    "\n",
    "ax = compare_scores(\n",
    "    comparison.initial.tolist(),\n",
    "    comparison.initial.tolist(),\n",
    "    \"Identity\",\n",
    "    color=\"#555555\",\n",
    ")\n",
    "ax = compare_scores(\n",
    "    comparison.initial.tolist(),\n",
    "    comparison.extract.tolist(),\n",
    "    \"Extract\",\n",
    "    ax=ax,\n",
    "    color=\"#c10078\",\n",
    ")\n",
    "\n",
    "ax = compare_scores(\n",
    "    comparison.initial.tolist(),\n",
    "    comparison.initial.sample(frac=1).tolist(),\n",
    "    \"Random\",\n",
    "    ax=ax,\n",
    "    color=\"#cccccc\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Ranked scores from Synthea records\")\n",
    "ax.set_ylabel(\"Agreement following NER extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priv_fp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
