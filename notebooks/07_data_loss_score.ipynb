{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2742aa",
   "metadata": {},
   "source": [
    "# 07 - Contrasting privacy score between source structured records and clinical note extraction\n",
    "\n",
    "In notebook 3, the data loss of individual identifiers from the original Synthea record to the extracts generated by the NER were compared. In this notebook the effect this loss has on the privacy risk score is examined.\n",
    "\n",
    "The approach taken is to compute the privacy risk score on both the Synthea records and the extracted records. Ideally, there would be perfect agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e293e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.common.config import (\n",
    "    load_experiment_config,\n",
    "    load_experiment_config_from_file,\n",
    "    load_global_config_from_file,\n",
    ")\n",
    "\n",
    "# Example config files are available in the config directory.\n",
    "# They will need to be modified with the path to the Julia executable\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_config.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5868b92-5302-4384-9584-c04395b561d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = load_experiment_config()\n",
    "experiment_config.scoring.encoding_scheme = \"rarest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import privacy_fingerprint.extract.aws_comprehend as aws\n",
    "import privacy_fingerprint.generate.synthea as synthea\n",
    "from privacy_fingerprint.score import PrivacyRiskScorer, encode, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset will be loaded from the directory created in notebook 2.\n",
    "output_dir = \"../../local/experiment_data/\"\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\")) as fp:\n",
    "    synthea_records = json.load(fp)\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\")) as fp:\n",
    "    llm_results = json.load(fp)\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\")) as fp:\n",
    "    ner_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8dc1f",
   "metadata": {},
   "source": [
    "## Generate scores on extracted records\n",
    "\n",
    "The following cells calculate the privacy risk score as in the other notebooks using the entire pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The format of the NER records must be standardised to enable scoring\n",
    "common_ner_results = aws.prepare_common_records(\n",
    "    aws.DEFAULT_IDENTIFIERS, ner_records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_dataset = preprocess(common_ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170451f-43eb-4b2d-8100-1f50117eb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_ethnicity(text):\n",
    "    text = text.lower()\n",
    "    if text == \"\":\n",
    "        return \"unknown\"\n",
    "    mentions = defaultdict(int)\n",
    "    for ethnicity, label in [\n",
    "        (\"white\", \"white\"),\n",
    "        (\"black\", \"black\"),\n",
    "        (\"african\", \"black\"),\n",
    "        (\"asian\", \"asian\"),\n",
    "        (\"indian\", \"asian\"),\n",
    "        (\"pakistani\", \"asian\"),\n",
    "        (\"chinese\", \"asian\"),\n",
    "    ]:\n",
    "        if ethnicity in text:\n",
    "            mentions[label] += 1\n",
    "    if len(mentions) > 1:\n",
    "        return \"mixed\"\n",
    "    elif len(mentions) == 1:\n",
    "        return list(mentions.keys())[0]\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def simplify_date_of_birth(date):\n",
    "    dt = pd.to_datetime(date, errors=\"coerce\")\n",
    "    if pd.isnull(dt):\n",
    "        return None\n",
    "    else:\n",
    "        return 10 * (dt.year // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    \"gender\": lambda x: x.lower()\n",
    "    if x.lower() in [\"female\", \"male\"]\n",
    "    else \"unknown\",\n",
    "    \"ethnicity\": simplify_ethnicity,\n",
    "    \"date_of_birth\": simplify_date_of_birth,\n",
    "}\n",
    "\n",
    "cols = [\n",
    "    \"date_of_birth\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"disease\",\n",
    "    \"symptoms\",\n",
    "    \"treatment\",\n",
    "    \"prescriptions\",\n",
    "]\n",
    "\n",
    "\n",
    "encoded_dataset, lookup = encode(\n",
    "    pcm_dataset[cols].transform(\n",
    "        {i: transformations.get(i, lambda x: x) for i in cols}\n",
    "    )\n",
    ")\n",
    "scorer = PrivacyRiskScorer()\n",
    "population_score = scorer.calculate_population_uniqueness(encoded_dataset)\n",
    "print(population_score)\n",
    "scorer.fit(encoded_dataset)\n",
    "#     individual_scores = scorer.predict(encoded_dataset)\n",
    "e2e = {\n",
    "    \"population_score\": population_score,\n",
    "    \"individual_scores\": scorer.predict(encoded_dataset),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739a3a8",
   "metadata": {},
   "source": [
    "## Generate scores on Synthea records\n",
    "\n",
    "The following cells calculate the privacy risk scores using the original Synthea records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_results = synthea.prepare_common_records(\n",
    "    synthea.DEFAULT_IDENTIFIERS, synthea_records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef85889",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthea_pcm_dataset = preprocess(common_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80af0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    \"gender\": lambda x: x.lower()\n",
    "    if x.lower() in [\"female\", \"male\"]\n",
    "    else \"unknown\",\n",
    "    \"ethnicity\": simplify_ethnicity,\n",
    "    \"date_of_birth\": simplify_date_of_birth,\n",
    "}\n",
    "\n",
    "cols = [\n",
    "    \"date_of_birth\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"disease\",\n",
    "    \"symptoms\",\n",
    "    \"treatment\",\n",
    "    \"prescriptions\",\n",
    "]\n",
    "\n",
    "\n",
    "encoded_dataset, lookup = encode(\n",
    "    synthea_pcm_dataset[cols].transform(\n",
    "        {i: transformations.get(i, lambda x: x) for i in cols}\n",
    "    )\n",
    ")\n",
    "scorer = PrivacyRiskScorer()\n",
    "population_score = scorer.calculate_population_uniqueness(encoded_dataset)\n",
    "print(population_score)\n",
    "scorer.fit(encoded_dataset)\n",
    "#     individual_scores = scorer.predict(encoded_dataset)\n",
    "initial_records = {\n",
    "    \"population_score\": population_score,\n",
    "    \"individual_scores\": scorer.predict(encoded_dataset),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13539b",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Population uniqueness on initial records\",\n",
    "    initial_records[\"population_score\"],\n",
    ")\n",
    "print(\"Population uniqueness on extracted records\", e2e[\"population_score\"])\n",
    "\n",
    "print(\n",
    "    \"Correlation between privacy risk scores on the initial Synthea records and extracted records\",\n",
    "    initial_records[\"individual_scores\"].corr(e2e[\"individual_scores\"]),\n",
    ")\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(initial_records[\"individual_scores\"], e2e[\"individual_scores\"], \"k.\")\n",
    "ax.set_xlabel(\"Initial structured records\")\n",
    "ax.set_ylabel(\"NER extracted records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc6b06-9804-43b3-bfd4-4a69a6076a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame()\n",
    "\n",
    "df_plot[\"init_ius\"] = initial_records[\"individual_scores\"]\n",
    "df_plot[\"e2e_ius\"] = e2e[\"individual_scores\"]\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    data=df_plot,\n",
    "    x=\"init_ius\",\n",
    "    y=\"e2e_ius\",\n",
    "    # kind=\"scatter\",\n",
    "    xlim=(-0.01, 1.01),\n",
    "    ylim=(-0.01, 1.01),\n",
    "    # s=5\n",
    ")\n",
    "g.plot_joint(sns.scatterplot, s=5, alpha=0.85)\n",
    "g.plot_marginals(sns.histplot, bins=25)\n",
    "\n",
    "g.ax_joint.set_xlabel(\"Initial structured records\")\n",
    "g.ax_joint.set_ylabel(\"NER extracted records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1da3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"initial\": initial_records[\"individual_scores\"],\n",
    "        \"extract\": e2e[\"individual_scores\"],\n",
    "    }\n",
    ")\n",
    "comparison[\"difference\"] = (comparison.initial - comparison.extract).abs()\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine individual records with the largest difference in score\n",
    "\n",
    "for idx in comparison.sort_values(\"difference\", ascending=False).index[:10]:\n",
    "    print(comparison.loc[idx])\n",
    "    for key in common_results[idx].dict().keys():\n",
    "        if key not in cols:\n",
    "            continue\n",
    "        print(\n",
    "            \"{0:<15} {1:<30} {2}\".format(\n",
    "                key,\n",
    "                str(common_results[idx].dict()[key]),\n",
    "                str(common_ner_results[idx].dict()[key]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the ordering of records by privacy risk in the Synthea and extracted datasets\n",
    "\n",
    "\n",
    "def compare_scores(a, b, label, ax=None, color=None):\n",
    "    assert len(a) == len(b), \"Lengths must match\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    c = pd.DataFrame({\"a\": a, \"b\": b})\n",
    "    c = c.sort_values(\"b\")\n",
    "    c[\"b_rank\"] = range(1, 1 + len(a))\n",
    "    c = c.sort_values(\"a\")\n",
    "    c[\"a_rank\"] = range(1, 1 + len(a))\n",
    "    fraction_below = []\n",
    "    for i in range(len(a)):\n",
    "        fraction_below.append((c.iloc[:i].b_rank <= c.iloc[i].a_rank).sum())\n",
    "    if color:\n",
    "        ax.plot(fraction_below, label=label, color=color)\n",
    "    else:\n",
    "        ax.plot(fraction_below, label=label)\n",
    "    return ax\n",
    "\n",
    "\n",
    "ax = compare_scores(\n",
    "    comparison.initial.tolist(),\n",
    "    comparison.initial.tolist(),\n",
    "    \"Identity\",\n",
    "    color=\"#555555\",\n",
    ")\n",
    "ax = compare_scores(\n",
    "    comparison.initial.tolist(),\n",
    "    comparison.extract.tolist(),\n",
    "    \"Extract\",\n",
    "    ax=ax,\n",
    "    color=\"#c10078\",\n",
    ")\n",
    "\n",
    "ax = compare_scores(\n",
    "    comparison.initial.tolist(),\n",
    "    comparison.initial.sample(frac=1).tolist(),\n",
    "    \"Random\",\n",
    "    ax=ax,\n",
    "    color=\"#cccccc\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Ranked scores from Synthea records\")\n",
    "ax.set_ylabel(\"Agreement following NER extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d0dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
