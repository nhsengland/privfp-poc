{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2742aa",
   "metadata": {},
   "source": [
    "# 02 - Generating Dataset 1\n",
    "\n",
    "The purpose of this notebook is to create a dataset that will be used for testing the performance of the package and conducting a series of experiments.\n",
    "\n",
    "By separating the creation of the dataset from its use it should be easier to re-use the dataset for the different tests and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e293e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.common.config import (\n",
    "    load_global_config_from_file,\n",
    "    load_experiment_config_from_file,\n",
    "    load_experiment_config,\n",
    ")\n",
    "import privacy_fingerprint.generate.synthea as synthea\n",
    "import privacy_fingerprint.generate.language_model as llm\n",
    "import privacy_fingerprint.extract.aws_comprehend as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example config files are available in the config directory.\n",
    "# These files will need to be customised with your API keys.\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_config.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")\n",
    "\n",
    "# Config options can be modified inline. To keep this notebook/experiment small\n",
    "# the number of records will be changed to 10.\n",
    "expt_config = load_experiment_config()\n",
    "expt_config.synthea.encounter_type = \"Encounter for symptom\"\n",
    "expt_config.synthea.num_records = 10  # 100_000 used to create dataset1\n",
    "load_experiment_config(expt_config.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Synthea output will be saved to a directory\n",
    "output_dir = \"../experiments/02_generate_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "export_directory = os.path.join(output_dir, \"synthea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa65aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: Given the number of records, running this cell will be extremely slow.\n",
    "\n",
    "# Generate structured records\n",
    "synthea_records = synthea.generate_records(export_directory)\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(synthea_records, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ead513",
   "metadata": {},
   "source": [
    "A modified version of the above was run. This generated 100k records in Synthea but then limited the import of those records to 1000. This then formed our dataset1. The records generated in our run are available separately to this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\")) as fp:\n",
    "    synthea_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0738cc8",
   "metadata": {},
   "source": [
    "The structured notes from Synthea can then be converted to free-text clinical notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note_generator = llm.LMGenerator()\n",
    "llm_results = list(clinical_note_generator.generate_text(synthea_records))\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(llm_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e23603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\")) as fp:\n",
    "    llm_results = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NER step using AWS ComprehendMedical is the most expensive step.\n",
    "# The cost can be estimated with the following function:\n",
    "\n",
    "print(\"Estimated cost is $\", aws.calculate_ner_cost(llm_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_extract = aws.ComprehendExtractor()\n",
    "ner_records = [aws_extract.extract_record(r) for r in llm_results]\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\"), \"w\") as fp:\n",
    "    json.dump(ner_records, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a previously generated set of records they can be loaded as follows:\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\")) as fp:\n",
    "    ner_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd1b0f",
   "metadata": {},
   "source": [
    "With the raw NER results generated, experiments will move to individual notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
