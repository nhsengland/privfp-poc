{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2742aa",
   "metadata": {},
   "source": [
    "# 06 - Investigating effect of dataset size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d258c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e293e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_fingerprint.common.config import (\n",
    "    load_experiment_config,\n",
    "    load_experiment_config_from_file,\n",
    "    load_global_config_from_file,\n",
    ")\n",
    "\n",
    "# Example config files are available in the config directory.\n",
    "# They will need to be modified with the path to the Julia executable\n",
    "\n",
    "load_global_config_from_file(\"../configs/global_config.yaml\")\n",
    "load_experiment_config_from_file(\"../configs/experiment_config.yaml\")\n",
    "\n",
    "experiment_config = load_experiment_config()\n",
    "experiment_config.scoring.encoding_scheme = \"rarest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import privacy_fingerprint.extract.aws_comprehend as aws\n",
    "from privacy_fingerprint.score import PrivacyRiskScorer, encode, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset will be loaded from the directory created in notebook 2.\n",
    "output_dir = \"../experiments/02_generate_dataset\"\n",
    "\n",
    "with open(os.path.join(output_dir, \"synthea_dataset.json\")) as fp:\n",
    "    synthea_records = json.load(fp)\n",
    "\n",
    "with open(os.path.join(output_dir, \"llm_dataset.json\")) as fp:\n",
    "    llm_results = json.load(fp)\n",
    "\n",
    "with open(os.path.join(output_dir, \"ner_dataset.json\")) as fp:\n",
    "    ner_records = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The format of the NER records must be standardised to enable scoring\n",
    "common_ner_results = aws.prepare_common_records(\n",
    "    aws.DEFAULT_IDENTIFIERS, ner_records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_dataset = preprocess(common_ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_ethnicity(text):\n",
    "    text = text.lower()\n",
    "    if text == \"\":\n",
    "        return \"unknown\"\n",
    "    mentions = defaultdict(int)\n",
    "    for ethnicity, label in [\n",
    "        (\"white\", \"white\"),\n",
    "        (\"black\", \"black\"),\n",
    "        (\"african\", \"black\"),\n",
    "        (\"asian\", \"asian\"),\n",
    "        (\"indian\", \"asian\"),\n",
    "        (\"pakistani\", \"asian\"),\n",
    "        (\"chinese\", \"asian\"),\n",
    "    ]:\n",
    "        if ethnicity in text:\n",
    "            mentions[label] += 1\n",
    "    if len(mentions) > 1:\n",
    "        return \"mixed\"\n",
    "    elif len(mentions) == 1:\n",
    "        return list(mentions.keys())[0]\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def simplify_date_of_birth(date):\n",
    "    dt = pd.to_datetime(date, errors=\"coerce\")\n",
    "    if pd.isnull(dt):\n",
    "        return None\n",
    "    else:\n",
    "        return 10 * (dt.year // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9174c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can be very slow to run\n",
    "\n",
    "transformations = {\n",
    "    \"gender\": lambda x: x.lower()\n",
    "    if x.lower() in [\"female\", \"male\"]\n",
    "    else \"unknown\",\n",
    "    \"ethnicity\": simplify_ethnicity,\n",
    "    \"date_of_birth\": simplify_date_of_birth,\n",
    "}\n",
    "\n",
    "cols = [\n",
    "    \"date_of_birth\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"disease\",\n",
    "    \"symptoms\",\n",
    "    \"treatment\",\n",
    "    \"prescriptions\",\n",
    "]\n",
    "size_results = []\n",
    "for repeat in range(10):\n",
    "    idx = pcm_dataset.index.tolist()\n",
    "    np.random.shuffle(idx)\n",
    "    for dataset_size in [1000, 750, 500, 250, 100]:\n",
    "        encoded_dataset, lookup = encode(\n",
    "            pcm_dataset.loc[idx[:dataset_size], cols].transform(\n",
    "                {i: transformations.get(i, lambda x: x) for i in cols}\n",
    "            )\n",
    "        )\n",
    "        scorer = PrivacyRiskScorer()\n",
    "        population_score = scorer.calculate_population_uniqueness(\n",
    "            encoded_dataset\n",
    "        )\n",
    "        print(population_score)\n",
    "        scorer.fit(encoded_dataset)\n",
    "        #     individual_scores = scorer.predict(encoded_dataset)\n",
    "        size_results.append(\n",
    "            {\n",
    "                \"repeat\": repeat,\n",
    "                \"size\": dataset_size,\n",
    "                \"population_score\": population_score,\n",
    "                \"individual_scores\": scorer.predict(encoded_dataset),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d41800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(\n",
    "    size_results,\n",
    "    os.path.join(output_dir, \"dataset_size_score_comparison.joblib\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aab770",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_results = joblib.load(\n",
    "    os.path.join(output_dir, \"dataset_size_score_comparison.joblib\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c82432",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_comparison = pd.DataFrame(size_results)\n",
    "pop_comparison = pop_comparison.drop(\"individual_scores\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "pop_comparison.plot.box(ax=ax, by=\"size\", column=\"population_score\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_xlabel(\"Dataset size\")\n",
    "ax.set_title(\"Population privacy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scores for the same 100 records in each dataset size is compared\n",
    "\n",
    "repeats = sorted(list(set([i[\"repeat\"] for i in size_results])))\n",
    "sampling_summary = []\n",
    "for r in repeats:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    repeat_results = {i[\"size\"]: i for i in size_results if i[\"repeat\"] == r}\n",
    "    print(len(repeat_results))\n",
    "    for k in repeat_results.keys():\n",
    "        repeat_subset = repeat_results[k][\"individual_scores\"].loc[\n",
    "            repeat_results[100][\"individual_scores\"].index\n",
    "        ]\n",
    "        repeat_subset.plot.kde(\n",
    "            ax=ax,\n",
    "            label=str(k),\n",
    "            ind=np.linspace(0, 1, 41),\n",
    "        )\n",
    "        repeat_subset.median()\n",
    "        sampling_summary.append(\n",
    "            {\n",
    "                \"repeat\": r,\n",
    "                \"size\": k,\n",
    "                \"median\": repeat_subset.median(),\n",
    "                \"mean\": repeat_subset.mean(),\n",
    "            }\n",
    "        )\n",
    "    ax.set_yscale(\"symlog\")\n",
    "    ax.set_ylim(0, 1000)\n",
    "    ax.legend()\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "sampling_summary = pd.DataFrame(sampling_summary)\n",
    "sampling_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_summary.plot.box(by=\"size\", column=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d89d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sampling_summary.plot.box(ax=ax, by=\"size\", column=\"mean\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_xlabel(\"Dataset size\")\n",
    "ax.set_title(\"Mean individual record privacy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92f7a1-c88a-4d74-8638-1f07a8088736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
